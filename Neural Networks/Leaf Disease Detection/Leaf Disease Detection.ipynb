{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ9Um8h0xpy8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwO9y6OHyEsx"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PLr7v0IyN7m"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz_ALwL3yO5N"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d mohitsingh1804/plantvillage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxnTs_ahyUh6"
      },
      "outputs": [],
      "source": [
        "!unzip plantvillage.zip -d /content/PlantVillage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OeewyhztybUC"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import io\n",
        "\n",
        "# Fix output encoding\n",
        "# sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
        "\n",
        "# Step 1: Data Preparation\n",
        "# Using ImageDataGenerator for data augmentation and rescaling\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,           # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,        # Random rotation\n",
        "    width_shift_range=0.2,    # Random horizontal shifts\n",
        "    height_shift_range=0.2,   # Random vertical shifts\n",
        "    shear_range=0.2,          # Random shear transformations\n",
        "    zoom_range=0.2,           # Random zoom transformations\n",
        "    horizontal_flip=True,     # Randomly flip images horizontally\n",
        "    fill_mode='nearest',      # Fill in new pixels\n",
        "    validation_split=0.2      # Use 20% of the data for validation\n",
        ")\n",
        "\n",
        "# Load training data from directory, with training and validation split\n",
        "train_generator = train_data_gen.flow_from_directory(\n",
        "    '/content/PlantVillage/PlantVillage/train',  # The root directory containing all class subfolders\n",
        "    target_size=(224, 224),   #\tThe images are resized to 224x224 pixels\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',   # indicates multi-class classification.\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_data_gen.flow_from_directory(\n",
        "    '/content/PlantVillage/PlantVillage/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Step 2: Model Building\n",
        "# Use VGG16 pre-trained on ImageNet as a base model for transfer learning\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the layers\n",
        "\n",
        "# Add custom layers for the new classification task\n",
        "model = Sequential([\n",
        "    Input(shape=(224, 224, 3)),  # Explicit input layer\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')  # Output layer for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model's architecture\n",
        "base_model.summary()  # Check the base model\n",
        "model.summary()       # Check the complete model\n",
        "\n",
        "\n",
        "# Step 3: Train the Model\n",
        "# Add learning rate reduction callback\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Training the model with the training and validation data\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,                        # Increased number of training epochs\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "# Evaluate the trained model on the validation data\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "# Step 5: Plot Training History\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Step 6: Save the Model\n",
        "# Save the trained model for future use\n",
        "model.save('leaf_disease_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}